# -*- org -*-

Datastores are a fundamental concept binding the data models written
in the YANG data modeling language to network management protocols
such as NETCONF and RESTCONF.  This document defines an architectural
framework for datastores based on the experience gained with the
initial simpler model, addressing requirements that were not well
supported in the initial model.

* Introduction

This document provides an architectural framework for
datastores as they are used by network management protocols such as
NETCONF ^RFC6241^, RESTCONF ^RFC8040^ and the YANG
^RFC7950^ data modeling language.  Datastores are a fundamental concept
binding network management data models to network management protocols.
Agreement on a common architectural model of datastores ensures that
data models can be written in a network management protocol agnostic
way.  This architectural framework identifies a set of conceptual
datastores but it does not mandate that all network management
protocols expose all these conceptual datastores.  This architecture
is agnostic with regard to the encoding used by network management
protocols.

* Terminology

This document defines the following terms:

- datastore: A conceptual place to store and access information.  A
  datastore might be implemented, for example, using files, a
  database, flash memory locations, or combinations thereof.
  A datastore maps to an instantiated YANG data tree.
- configuration: Data that determines how a device behaves.
  This data is modeled in YANG using "config true" nodes.
  Configuration can originate from different sources.
- configuration datastore: A datastore holding configuration.
- running configuration datastore: A configuration datastore holding
  the current configuration of the device.  It may include
  inactive configuration or template-mechanism-oriented configuration
  that require further expansion.  This datastore is commonly
  referred to as "<running>".
- candidate configuration datastore: A configuration datastore that
  can be manipulated without impacting the device's running
  configuration datastore and that can be committed to the running
  configuration datastore.  This datastore is commonly referred to as
  "<candidate>".
- startup configuration datastore: A configuration datastore holding
  the configuration loaded by the device into the running
  configuration datastore when it boots.  This datastore is commonly
  referred to as "<startup>".
- intended configuration: Configuration that is intended to
  be used by the device.  For example, intended configuration excludes any
  inactive configuration and it would include configuration
  produced through the expansion of templates.
- intended configuration datastore: A configuration datastore holding
  the complete intended configuration of the device.  This datastore
  is commonly referred to as "<intended>".
- conventional configuration datastore: One of the following set of
  configuration datastores: <running>, <startup>, <candidate>, and
  <intended>.  These datastores share a common schema and protocol
  operations allow copying data between these datastores.  The term
  "conventional" is chosen as a generic umbrella term for these
  datastores.
- conventional configuration: Configuration that is stored
  in any of the conventional configuration datastores.
- dynamic configuration: Configuration obtained dynamically during the
  operation of a device through interaction with other systems and
  which is not conventional configuration.
- dynamic datastore: A datastore holding data obtained dynamically
  during the operation of a device through interaction with other
  systems. A dynamic datastore may hold dynamic configuration.
- applied configuration: Configuration that is currently
  used by a device. Applied configuration consists of conventional
  configuration and dynamic configuration.
- system state: The additional data on a system that is not
  configuration, such as read-only status information and
  collected statistics. System state is transient and modified by
  interactions with internal components or other systems.
  System state is modeled in YANG using "config false" nodes.
- system configuration: Configuration that is supplied by
  the device itself.
- default configuration: Configuration that is not
  explicitly provided but for which a value defined in the data model
  is used.
- operational state: The combination of applied configuration,
  system configuration, default configuration, and system state.
- operational state datastore: A datastore holding the
  complete operational state of the device.  This datastore
  is commonly referred to as "<operational>".
- origin: A metadata annotation indicating the origin of a data item.
- remnant configuration: Configuration that remains in the
  applied configuration datastore for a period of time after it has be
  removed from intended configuration or dynamic configuration.
  The time period may be minimal, or may last until all
  resources used by the newly-deleted configuration (e.g.,
  network connections, memory allocations, file handles) have been
  deallocated.

The following additional terms are not datastore specific but commonly
used and thus defined here as well:

- client: An entity that can access YANG-defined data on a server,
  over some network management protocol.
- server: An entity that provides access to YANG-defined data to a
  client, over some network management protocol.
- notification: A server-initiated message indicating that a certain
  event has been recognized by the server.
- remote procedure call: An operation that can be invoked by a client
  on a server.

* Background

NETCONF ^RFC6241^ provides the following definitions:

- datastore: A conceptual place to store and access information.  A
  datastore might be implemented, for example, using files, a
  database, flash memory locations, or combinations thereof.
- configuration datastore: The datastore holding the complete set of
  configuration that is required to get a device from its initial
  default state into a desired operational state.

YANG 1.1 ^RFC7950^ provides the following
refinements when NETCONF is used with YANG (which is the usual case
but note that NETCONF was defined before YANG existed):

- datastore: When modeled with YANG, a datastore is realized as an
  instantiated data tree.
- configuration datastore: When modeled with YANG, a configuration
  datastore is realized as an instantiated data tree with
  configuration.

^RFC6244^ defined operational state data as follows:

- Operational state data is a set of data that has been obtained by
  the system at runtime and influences the system's behavior similar
  to configuration data.  In contrast to configuration data,
  operational state is transient and modified by interactions with
  internal components or other systems via specialized protocols.

Section 4.3.3 of ^RFC6244^ discusses operational state and among other
things mentions the option to consider operational state as being
stored in another datastore.  Section 4.4 of this document then
concludes that at the time of the writing, modeling state as distinct
leafs and distinct branches is the recommended approach.

Implementation experience and requests from operators
^I-D.ietf-netmod-opstate-reqs^, ^I-D.openconfig-netmod-opstate^
indicate that the datastore model initially designed for NETCONF and
refined by YANG needs to be extended.  In particular, the notion of
intended configuration and applied configuration has developed.

Furthermore, separating operational state from configuration
in a separate branch in the data model has been found operationally
complicated, and typically impacts the readability of module
definitions due to overuse of groupings.  The relationship between the
branches is not machine readable and filter expressions operating on
configuration and on related operational state are
different.

** Original Model of Datastores

The following drawing shows the original model of datastores as it is
currently used by NETCONF ^RFC6241^:

#+BEGIN_EXAMPLE
  +-------------+                 +-----------+
  | <candidate> |                 | <startup> |
  |  (ct, rw)   |<---+       +--->| (ct, rw)  |
  +-------------+    |       |    +-----------+
         |           |       |           |
         |         +-----------+         |
         +-------->| <running> |<--------+
                   | (ct, rw)  |
                   +-----------+
                         |
                         v
                  operational state  <--- control plane
                      (cf, ro)

  ct = config true; cf = config false
  rw = read-write; ro = read-only
  boxes denote datastores

#+END_EXAMPLE

Note that this diagram simplifies the model: read-only (ro) and
read-write (rw) is to be understood at a conceptual level.  In
NETCONF, for example, support for <candidate> and <startup> is
optional and <running> does not have to be writable.  Furthermore,
<startup> can only be modified by copying <running> to <startup> in
the standardized NETCONF datastore editing model.  The RESTCONF
protocol does not expose these differences and instead provides only a
writable unified datastore, which hides whether edits are done through
<candidate> or by directly modifying <running> or via some other
implementation specific mechanism.  RESTCONF also hides how
configuration is made persistent.  Note that implementations may also
have additional datastores that can propagate changes to <running>.
NETCONF explicitly mentions so called named datastores.

Some observations:

- Operational state has not been defined as a datastore although there
  were proposals in the past to introduce an operational state
  datastore.
- The NETCONF <get/> operation returns the content of the <running>
  configuration datastore together with the operational state.  It is
  therefore necessary that "config false" data is in a different branch
  than the "config true" data if the operational state can have a
  different lifetime compared to configuration or if
  configuration is not immediately or successfully applied.
- Several implementations have proprietary mechanisms that allow
  clients to store inactive data in <running>; this
  inactive data is only exposed to clients that indicate that they
  support the concept of inactive data; clients not indicating support
  for inactive data receive the content of <running>
  with the inactive data removed.  Inactive data is conceptually
  removed before validation.
- Some implementations have proprietary mechanisms that allow clients
  to define configuration templates in <running>.  These
  templates are expanded automatically by the system, and the
  resulting configuration is applied internally.
- Some operators have reported that it is essential for them to be
  able to retrieve the configuration that has actually been
  successfully applied, which may be a subset or a superset of the
  <running> configuration.

* Architectural Model of Datastores @datastore-model@

Below is a new conceptual model of datastores extending the original
model in order to reflect the experience gained with the original
model.

#+BEGIN_EXAMPLE
  +-------------+                 +-----------+
  | <candidate> |                 | <startup> |
  |  (ct, rw)   |<---+       +--->| (ct, rw)  |
  +-------------+    |       |    +-----------+
         |           |       |           |
         |         +-----------+         |
         +-------->| <running> |<--------+
                   | (ct, rw)  |
                   +-----------+
                         |
                         |        // e.g., removal of "inactive"
                         |        // nodes, expansion of templates
                         v
                   +------------+
                   | <intended> | // subject to validation
                   | (ct, ro)   |
                   +------------+
                         |
                         |        // e.g., missing resources, delays
                         |
                         |   +------ auto-discovery
                         |   +------ dynamic configuration protocols
                         |   +------ control-plane protocols
                         |   +------ dynamic datastores
                         |   +------ system configuration
                         |   +------ default configuration
                         |   |
                         v   v
                 +---------------+
                 | <operational> |
                 | (ct + cf, ro) |
                 +---------------+

  ct = config true; cf = config false
  rw = read-write; ro = read-only
  boxes denote datastores

#+END_EXAMPLE

** The Startup Configuration Datastore (<startup>)

The startup configuration datastore (<startup>) is an optional
configuration datastore holding the configuration loaded by the device
when it boots.  <startup> is only present on devices that separate the
startup configuration from the running configuration datastore.

The startup configuration datastore may not be supported by all
protocols or implementations.

** The Candidate Configuration Datastore (<candidate>)

The candidate configuration datastore (<candidate>) is an optional
configuration datastore that can be manipulated without impacting the
device's current configuration and that can be committed to <running>.

The candidate configuration datastore may not be supported by all
protocols or implementations.

** The Running Configuration Datastore (<running>)

The running configuration datastore (<running>) holds the complete
current configuration on the device.  It may include inactive
configuration or template-mechanism-oriented configuration that
require further expansion.

** The Intended Configuration Datastore (<intended>)

The intended configuration datastore (<intended>) is a read-only
configuration datastore.  It is tightly coupled to <running>.  When
data is written to <running>, the data that is to be validated is also
conceptually written to <intended>.  Validation is performed on the
contents of <intended>.

For simple implementations, <running> and <intended> are identical.

Currently there are no standard mechanisms defined that affect
<intended> so that it would have different contents than <running>,
but this architecture allows for such mechanisms to be defined.

One example of such a mechanism is support for marking nodes as
inactive in <running>.  Inactive nodes are not copied to <intended>,
and are thus not taken into account when validating the configuration.

Another example is support for templates.  Templates are expanded
when copied into <intended>, and the expanded result is validated.

** Conventional Configuration Datastores

The conventional configuration datastores are a set of configuration
datastores that share a common schema, allowing data to be copied
between them.  The term is meant as a generic umbrella description of
these datastores.  The set of datastores include:

- <running>
- <candidate>
- <startup>
- <intended>

Other conventional configuration datastores may be defined in future
documents.

The flow of data between these datastores is depicted in section
^datastore-model^.

The specific protocols may define explicit operations to copy between
these datastores, e.g. NETCONF's <copy-config> operation.

** Dynamic Datastores

The model recognizes the need for dynamic datastores that are, by
definition, not part of the persistent configuration of a device.  In
some contexts, these have been termed ephemeral datastores since the
information is ephemeral, i.e., lost upon reboot.  The dynamic
datastores interact with the rest of the system through <operational>.

** The Operational State Datastore (<operational>)

The operational state datastore (<operational>) is a read-only
datastore that consists of all "config true" and "config false" nodes
defined in the schema.  In the original NETCONF model the operational
state only had "config false" nodes.  The reason for incorporating
"config true" nodes here is to be able to expose all operational
settings without having to replicate definitions in the data models.

<operational> contains system state and all configuration actually
used by the system.  This includes all applied configuration from
<intended>, system-provided configuration, and default values defined
by any supported data models.  In addition, <operational> also
contains applied data from dynamic datastores.

Changes to configuration may take time to percolate through to
<operational>.  During this period, <operational> may contain
nodes for both the previous and current configuration, as closely as
possible tracking the current operation of the device.  Such remnant
configuration from the previous configuration persists until the
system has released resources used by the newly-deleted configuration
(e.g., network connections, memory allocations, file handles).

As a result of remnant configuration, the semantic constraints defined
in the data model cannot be relied upon for <operational>, since the
system may have remnant configuration whose constraints were valid
with the previous configuration and that are not valid with the
current configuration.  Since constraints on "config false" nodes may
refer to "config true" nodes, remnant configuration may force the
violation of those constraints.  The constraints that may not hold
include "when", "must", "min-elements", and "max-elements".  Note that
syntactic constraints cannot be violated, including hierarchical
organization, identifiers, and type-based constraints.

*** Missing Resources

Configuration in <intended> can refer to resources that are not
available or otherwise not physically present.  In these situations,
these parts of the <intended> configuration are not applied.  The data
appears in <intended> but does not appear in <operational>.

A typical example is an interface configuration that refers to an
interface that is not currently present.  In such a situation, the
interface configuration remains in <intended> but the interface
configuration will not appear in <operational>.

Note that configuration validity cannot depend on the current state of
such resources, since that would imply the removing a resource might
render the configuration invalid.  This is unacceptable, especially
given that rebooting such a device would fail to boot due to an
invalid configuration.  Instead we allow configuration for missing
resources to exist in <running> and <intended>, but it will not appear
in <operational>.

*** System-controlled Resources

Sometimes resources are controlled by the device and the corresponding
system controlled data appear in (and disappear from) <operational>
dynamically.  If a system controlled resource has matching
configuration in <intended> when it appears, the system will try to
apply the configuration, which causes the configuration to appear in
<operational> eventually (if application of the configuration was
successful).

*** Origin Metadata Annotation

As data flows into <operational>, it is conceptually
marked with a metadata annotation (^RFC7952^) that indicates its
origin.  The "origin" metadata annotation is defined in ^yang-module^.
The values are YANG identities.  The following identities are defined:

- origin: abstract base identity from which the other identities are
  derived.
- intended: represents data provided by <intended>.
- dynamic: represents data provided by a dynamic datastore or a
  dynamic configuration protocol.
- default: represents data values specified in the data model, using
  either values in the "default" statement or any values
  described in the "description" statement.
- system: represents data learned from the normal operations of the
  system, including control-plane protocols.

These identities can be further refined, e.g., there could be an
identity "dhcp" derived from "dynamic".

* Implications on YANG

# TODO:
#
# if this arch is supported:
# - running doesn't have to be valid
# - intended is valid
# - no validation in operational
#
# Do we need more text than what we already have for the issues above?

** XPath Context

If a server implements the architecture defined in this document, the
accessible trees for some XPath contexts are refined as follows:

- If the XPath expression is defined in a substatement to a data node
  that represents system state, the accessible tree is all operational
  state in the server.  The root node has all top-level data
  nodes in all modules as children.
- If the XPath expression is defined in a substatement to a
  "notification" statement, the accessible tree is the notification
  instance and all operational state in the server.  If the
  notification is defined on the top level in a module, then the root
  node has the node representing the notification being defined and
  all top-level data nodes in all modules as children.  Otherwise, the
  root node has all top-level data nodes in all modules as children.
- If the XPath expression is defined in a substatement to an "input"
  statement in an "rpc" or "action" statement, the accessible tree is
  the RPC or action operation instance and all operational state
  in the server.  The root node has top-level data nodes in all modules
  as children.  Additionally, for an RPC, the root node also has the
  node representing the RPC operation being defined as a child.  The
  node representing the operation being defined has the operation's
  input parameters as children.
- If the XPath expression is defined in a substatement to an "output"
  statement in an "rpc" or "action" statement, the accessible tree is
  the RPC or action operation instance and all operational state
  in the server.  The root node has top-level data nodes in all modules
  as children.  Additionally, for an RPC, the root node also has the
  node representing the RPC operation being defined as a child.  The
  node representing the operation being defined has the operation's
  output parameters as children.

* Guidelines for Defining Datastores @guidelines@

The definition of a new datastore in this architecture should be
provided in a document (e.g., an RFC) purposed to the definition of
the datastore.  When it makes sense, more than one datastore may be
defined in the same document (e.g., when the datastores are logically
connected).  Each datastore's definition should address the points
specified in the sections below.

** Define a name for the datastore @def-name@

Each datastore must have a name using the character set
described by Section 6.2 of ^RFC7950^.  The name should be consistent
in style and length to other datastore names described in this
document.

The datastore's name does not need to be globally unique, as it will
be uniquely qualified by the namespace of the module in which it is
defined (^def-module^).  This means that names such as "running" and
"operational" are valid datastore names. However, it is usually
desirable to avoid using the same name for multiple different
datastores.

** Define which YANG modules can be used in the datastore

Not all YANG modules may be used in all datastores.  Some datastores may
constrain which data models can be used in them.  If it is desirable that
a subset of all modules can be targeted to the datastore,
then the documentation defining the datastore must indicate this.

** Define which subset of YANG-modeled data applies

By default, the data in a datastore is modeled by all YANG statements
in the available YANG modules.  However, it is possible to specify
criteria that YANG statements must satisfy in order to be present in a
datastore.  For instance, maybe only "config true" nodes are present, or
"config false nodes" that also have a specific YANG extension (e.g.,
"i2rs:ephemeral true") are present in the datastore.

** Define how data is actualized

The new datastore must specify how it interacts with other datastores.
For example, the diagram in ^datastore-model^ depicts dynamic
datastores feeding into <operational>.  How this
interaction occurs must be defined by any dynamic datastore.  In some
cases, it may occur implicitly, as soon as the data is put into the
dynamic datastore while, in other cases, an explicit action (e.g., an
RPC) may be required to trigger the application of the dynamic
datastore's data.

** Define which protocols can be used

By default, it is assumed that both the NETCONF and RESTCONF
protocols can be used to interact with a datastore.
However, it may be that only a specific protocol can be used
(e.g., ForCES) or that a subset of all protocol operations or
capabilities are available (e.g., no locking or no XPath-based
filtering).

** Define a module for the datastore @def-module@

Each datastore must be defined by a YANG module.
This module is used by servers to indicate (e.g., via YANG Library)
their support for the datastore.

The YANG module must import the "ietf-datastores" and "ietf-origin"
modules, defined in this document.  This is necessary in order to
access the base identities they define.

The YANG module must define an identity that uses the "ds:datastore"
identity or one of its derived identities as its base.  This identity
is necessary so that the datastore can be referenced in protocol
operations (e.g., <get-data>).

The YANG module may define an identity that uses the "or:origin"
identity or one its derived identities as its base.  This identity is
needed if the datastore interacts with <operational> so that data
originating from the datastore can be identified as such via the
"origin" metadata attribute defined in ^yang-module^.

An example of these guidelines in use is provided in
^ephemeral-ds-example^.

* YANG Modules @yang-module@

!! include-figure ietf-datastores.yang extract-to="ietf-datastores@2017-04-26.yang"

!! include-figure ietf-origin.yang extract-to="ietf-origin@2017-04-26.yang"

* IANA Considerations @iana-con@

** Updates to the IETF XML Registry

This document registers two URIs in the IETF XML registry ^RFC3688^.  Following
the format in ^RFC3688^, the following registrations are requested:

   URI: urn:ietf:params:xml:ns:yang:ietf-datastores
   Registrant Contact: The IESG.
   XML: N/A, the requested URI is an XML namespace.

   URI: urn:ietf:params:xml:ns:yang:ietf-origin
   Registrant Contact: The IESG.
   XML: N/A, the requested URI is an XML namespace.

** Updates to the YANG Module Names Registry

This document registers two YANG modules in the YANG Module Names registry
^RFC6020^.  Following the format in ^RFC6020^, the the following registrations
are requested:

   name:         ietf-datastores
   namespace:    urn:ietf:params:xml:ns:yang:ietf-datastores
   prefix:       ds
   reference:    RFC XXXX

   name:         ietf-origin
   namespace:    urn:ietf:params:xml:ns:yang:ietf-origin
   prefix:       or
   reference:    RFC XXXX

* Security Considerations @sec-con@

This document discusses an architectural model of datastores for network
management using NETCONF/RESTCONF and YANG.  It has no security impact
on the Internet.

* Acknowledgments

This document grew out of many discussions that took place since 2010.
Several Internet-Drafts (^I-D.bjorklund-netmod-operational^,
^I-D.wilton-netmod-opstate-yang^, ^I-D.ietf-netmod-opstate-reqs^,
^I-D.kwatsen-netmod-opstate^, ^I-D.openconfig-netmod-opstate^) and
^RFC6244^ touched on some of the problems of the original datastore
model.  The following people were authors to these Internet-Drafts or
otherwise actively involved in the discussions that led to this
document:

- Lou Berger, LabN Consulting, L.L.C., <lberger@labn.net>
- Andy Bierman, YumaWorks, <andy@yumaworks.com>
- Marcus Hines, Google, <hines@google.com>
- Christian Hopps, Deutsche Telekom, <chopps@chopps.org>
- Acee Lindem, Cisco Systems, <acee@cisco.com>
- Ladislav Lhotka, CZ.NIC, <lhotka@nic.cz>
- Thomas Nadeau, Brocade Networks, <tnadeau@lucidvision.com>
- Anees Shaikh, Google, <aashaikh@google.com>
- Rob Shakir, Google, <robjs@google.com>

Juergen Schoenwaelder was partly funded by Flamingo, a Network of
Excellence project (ICT-318488) supported by the European Commission
under its Seventh Framework Programme.

*! start-appendix

* Example Data

The use of datastores is complex, and many of the subtle effects are
more easily presented using examples.  This section presents a series
of example data models with some sample contents of the various
datastores.

** System Example

In this example, the following fictional module is used:

!! include-figure example-system.yang

The operator has configured the host name and two interfaces, so the
contents of <intended> is:

!! include-figure ex-intended.load

The system has detected that the hardware for one of the configured
interfaces ("eth1") is not yet present, so the configuration for that
interface is not applied.  Further, the system has received a host name
and an additional IP address for "eth0" over DHCP.  In addition to a
default value, a loopback interface is automatically added by the system,
and the result of the "speed" auto-negotiation.  All of this is reflected
in <operational>:

!! include-figure ex-oper.load

** BGP Example

Consider the following piece of a ersatz BGP module:

    container bgp {
      leaf local-as {
        type uint32;
      }
      leaf peer-as {
        type uint32;
      }
      list peer {
        key name;
        leaf name {
          type ipaddress;
        }
        leaf local-as {
          type uint32;
          description
            ".... Defaults to ../local-as";
        }
        leaf peer-as {
          type uint32;
          description
             "... Defaults to ../peer-as";
        }
        leaf local-port {
          type inet:port;
        }
        leaf remote-port {
          type inet:port;
          default 179;
        }
        leaf state {
          config false;
          type enumeration {
            enum init;
            enum established;
            enum closing;
          }
        }
      }
    }

In this example model, both bgp/peer/local-as and bgp/peer/peer-as
have complex hierarchical values, allowing the user to specify default
values for all peers in a single location.

The model also follows the pattern of fully integrating state ("config
false") nodes with configuration ("config true") nodes.  There is not
separate "bgp-state" hierarchy, with the accompanying repetition of
containment and naming nodes.  This makes the model simpler and more
readable.

*** Datastores

Each datastore represents differing views of these nodes.
<running> will hold the configuration provided by the user, for
example a single BGP peer.  <intended> will conceptually hold the data
as validated, after the removal of data not intended for validation
and after any local template mechanisms are performed.  <operational>
will show data from <intended> as well as any "config false" nodes.

*** Adding a Peer

If the user configures a single BGP peer, then that peer will be
visible in both <running> and <intended>.  It may also
appear in <candidate>, if the server supports the
"candidate" feature.  Retrieving the peer will return only the
user-specified values.

No time delay should exist between the appearance of the peer in
<running> and <intended>.

In this scenario, we've added the following to <running>:

  <bgp>
    <local-as>64642</local-as>
    <peer-as>65000</peer-as>
    <peer>
      <name>10.1.2.3</name>
    </peer>
  </bgp>

**** <operational>

<operational> will contain the fully expanded peer data,
including "config false" nodes.  In our example, this means the
"state" node will appear.

In addition, <operational> will contain the "currently in use" values
for all nodes.  This means that local-as and peer-as will be populated
even if they are not given values in <intended>.  The value of
bgp/local-as will be used if bgp/peer/local-as is not provided;
bgp/peer-as and bgp/peer/peer-as will have the same relationship.  In
the operational view, this means that every peer will have values for
their local-as and peer-as, even if those values are not explicitly
configured but are provided by bgp/local-as and bgp/peer-as.

Each BGP peer has a TCP connection associated with it, using the
values of local-port and remote-port from <intended>.  If
those values are not supplied, the system will select values.  When
the connection is established, <operational> will contain the current
values for the local-port and remote-port nodes regardless of the
origin.  If the system has chosen the values, the "origin" attribute
will be set to "operational".  Before the connection is established,
one or both of the nodes may not appear, since the system may not yet
have their values.

  <bgp origin="or:intended" xmlns="urn:example:bgp">
    <local-as origin="or:intended">64642</local-as>
    <peer-as origin="or:intended">65000</peer-as>
    <peer origin="or:intended">
      <name origin="or:intended">10.1.2.3</name>
      <local-as origin="or:default">64642</local-as>
      <peer-as origin="or:default">65000</peer-as>
      <local-port origin="or:system">60794</local-port>
      <remote-port origin="or:default">179</remote-port>
    </peer>
  </bgp>

*** Removing a Peer

Changes to configuration may take time to percolate through the
various software components involved.  During this period, it is
imperative to continue to give an accurate view of the working of the
device.  <operational> will contain nodes for both
the previous and current configuration, as closely as possible
tracking the current operation of the device.

Consider the scenario where a client removes a BGP peer.  When a peer
is removed, the operational state will continue to reflect the
existence of that peer until the peer's resources are released,
including closing the peer's connection.  During this period, the
current data values will continue to be visible in <operational>,
with the "origin" attribute set to indicate the
origin of the original data.

  <bgp origin="or:intended">
    <local-as origin="or:intended">64642</local-as>
    <peer-as origin="or:intended">65000</peer-as>
    <peer origin="or:intended">
      <name origin="or:intended">10.1.2.3</name>
      <local-as origin="or:default">64642</local-as>
      <peer-as origin="or:default">65000</peer-as>
      <local-port origin="or:intended">60794</local-port>
      <remote-port origin="or:intended">179</remote-port>
    </peer>
  </bgp>

Once resources are released and the connection is closed, the
peer's data is removed from <operational>.

** Interface Example

In this section, we'll use this simple interface data model:

  container interfaces {
    list interface {
      key name;
      leaf name {
        type string;
      }
      leaf description {
        type string;
      }
      leaf mtu {
        type uint;
      }
      leaf ipv4-address {
        type inet:ipv4-address;
      }
    }
  }

*** Pre-provisioned Interfaces

One common issue in networking devices is the support of Field
Replaceable Units (FRUs) that can be inserted and removed from the
device without requiring a reboot or interfering with normal
operation.  These FRUs are typically interface cards, and the devices
support pre-provisioning of these interfaces.

If a client creates an interface "et-0/0/0" but the interface does not
physically exist at this point, then <intended> might contain the
following:

  <interfaces>
    <interface>
      <name>et-0/0/0</name>
      <description>Test interface</description>
    </interface>
  </interfaces>

Since the interface does not exist, this data does not appear in
<operational>.

When a FRU containing this interface is inserted, the system will
detect it and process the associated configuration.  The <operational>
will contain the data from <intended>, as well as the "config false"
nodes, such as the current value of the interface's MTU.

  <interfaces origin="or:intended">
    <interface origin="or:intended">
      <name origin="or:intended">et-0/0/0</name>
      <description origin="or:intended">Test interface</description>
      <mtu origin="or:system">1500</mtu>
    </interface>
  </interfaces>

If the FRU is removed, the interface data is removed from
<operational>.

*** System-provided Interface

Imagine if the system provides a loopback interface (named "lo0") with
a default ipv4-address of "127.0.0.1".  The system will only provide
configuration for this interface if there is no data for it in <intended>.

When no configuration for "lo0" appears in <intended>, then
<operational> will show the system-provided data:

  <interfaces origin="or:intended">
    <interface origin="or:system">
      <name origin="or:system">lo0</name>
      <ipv4-address origin="or:system">127.0.0.1</ipv4-address>
    </interface>
  </interfaces>

When configuration for "lo0" does appear in <intended>, then
<operational> will show that data with the origin set to "intended".
If the "ipv4-address" is not provided, then the system-provided value
will appear as follows:

  <interfaces origin="or:intended">
    <interface origin="or:intended">
      <name origin="or:intended">lo0</name>
      <description origin="or:intended">loopback</description>
      <ipv4-address origin="or:system">127.0.0.1</ipv4-address>
    </interface>
  </interfaces>

* Ephemeral Dynamic Datastore Example @ephemeral-ds-example@

The section defines documentation for an example dynamic
datastore using the guidelines provided in ^guidelines^.
While this example is very terse, it is expected to be that a
standalone RFC would be needed when fully expanded.

This example defines a dynamic datastore called "ephemeral",
which is loosely modeled after the work done in the I2RS working
group.

  1. Name            : ephemeral
  2. YANG modules    : all (default)
  3. YANG statements : config false + ephemeral true
  4. How applied     : automatic
  5. Protocols       : NC/RC (default)
  6. YANG Module     : (see below)

!! include-figure example-ds-ephemeral.yang

# * Open Issues @issues@
#
# + NETCONF needs to be able to filter data based on the origin
#  metadata.  Possibly this could be done as part of the <get-data>
#  operation.


{{document:
    name ;
    ipr trust200902;
    category std;
    references references.xml;
    title "Network Management Datastore Architecture";
    contributor "author:Martin Bjorklund:Tail-f Systems:mbj@tail-f.com";
    contributor "author:Juergen Schoenwaelder:Jacobs University:j.schoenwaelder@jacobs-university.de";
    contributor "author:Phil Shafer:Juniper Networks:phil@juniper.net";
    contributor "author:Kent Watsen:Juniper Networks:kwatsen@juniper.net";
    contributor "author:Rob Wilton:Cisco Systems:rwilton@cisco.com";
}}
